{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–ª—è –≤—ã–±–æ—Ä–∫–∏ –æ–±—ä–µ–º–æ–º 25:\n",
      "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–∫—Ä—ã—Ç–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞: 0.948\n",
      "–î–ª—è –≤—ã–±–æ—Ä–∫–∏ –æ–±—ä–µ–º–æ–º 1000:\n",
      "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–∫—Ä—ã—Ç–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞: 0.952\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "mu_1 = 2\n",
    "mu_2 = 1\n",
    "sigma_1_squared = 1\n",
    "sigma_2_squared = 0.5\n",
    "alpha = 0.05\n",
    "repetitions = 1000\n",
    "\n",
    "real_tau = mu_1 - mu_2\n",
    "sample_sizes = [25, 1000]\n",
    "\n",
    "def confidence_interval(X, Y, alpha):\n",
    "    n1 = len(X)\n",
    "    n2 = len(Y)\n",
    "\n",
    "    std_diff = np.sqrt(sigma_1_squared / n1 + sigma_2_squared / n2)\n",
    "    standardized_diff = (np.mean(X) - np.mean(Y) - real_tau) / std_diff\n",
    "    z_alpha = norm.ppf(1 - alpha / 2)\n",
    "    lower_bound = standardized_diff - z_alpha\n",
    "    upper_bound = standardized_diff + z_alpha\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "def experiment(mu1, mu2, alpha, sample_size, experiments):\n",
    "    covered = 0\n",
    "    for _ in range(experiments):\n",
    "        X = np.random.normal(mu1, np.sqrt(sigma_1_squared), sample_size)\n",
    "        Y = np.random.normal(mu2, np.sqrt(sigma_2_squared), sample_size)\n",
    "        interval = confidence_interval(X, Y, alpha)\n",
    "        if interval[0] <= 0 <= interval[1]:\n",
    "            covered += 1\n",
    "    coverage_probability = covered / experiments\n",
    "    return coverage_probability\n",
    "\n",
    "for sample_size in sample_sizes:\n",
    "    coverage_probability = experiment(mu_1, mu_2, alpha, sample_size, repetitions)\n",
    "    print(f\"–î–ª—è –≤—ã–±–æ—Ä–∫–∏ –æ–±—ä–µ–º–æ–º {sample_size}:\")\n",
    "    print(f\"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–∫—Ä—ã—Ç–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞: {coverage_probability}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2\n",
    "–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –∞—Å–∏–º–ø—Ç–æ—Ç–∏—á–µ—Å–∫–∏–π –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª —É—Ä–æ–≤–Ω—è 1-ùõº  –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞  –ü—Ä–æ–≤–µ–¥–∏—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –ø–æ —Å—Ö–µ–º–µ, –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–π –ø–µ—Ä–≤–æ–π –∑–∞–¥–∞—á–µ. –ó–∞–¥–∞—á–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ 5 –≤–∞—Ä–∏–∞–Ω—Ç–∞—Ö. –°–Ω–∞—á–∞–ª–∞ —É–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –∫–ª–∞—Å—Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π (–æ–¥–Ω–æ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π) –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ–º—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä, –∑–∞—Ç–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –∏ –ø–æ–¥—Å–∫–∞–∑–∫–∏. \n",
    "Exp(ùúÜ); –º–µ–¥–∏–∞–Ω–∞;  ùúÜ = 1;  –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –ø—Ä–µ–¥–µ–ª—å–Ω–æ–π —Ç–µ–æ—Ä–µ–º–æ–π –æ–± –∞—Å–∏–º–ø—Ç–æ—Ç–∏—á–µ—Å–∫–æ–º –ø–æ–≤–µ–¥–µ–Ω–∏–∏ —Å—Ä–µ–¥–Ω–µ–≥–æ —á–ª–µ–Ω–∞ –≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ê—Å–∏–º–ø—Ç–æ—Ç–∏—á–µ—Å–∫–∏–π –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª —É—Ä–æ–≤–Ω—è 0.95 –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ lambda: (0.9653298253194655, 1.089288831780378)\n",
      "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–∫—Ä—ã—Ç–∏—è –∏—Å—Ç–∏–Ω–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ lambda: 0.95\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# –ó–∞–¥–∞–Ω–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä\n",
    "lambda_val = 1\n",
    "alpha = 0.05\n",
    "sample_size = 1000\n",
    "experiments = [10000]\n",
    "\n",
    "sample_mean = 1 / lambda_val\n",
    "sample_std_mean = 1 / (lambda_val * np.sqrt(sample_size))\n",
    "\n",
    "z_alpha_2 = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "covered_count = 0\n",
    "\n",
    "for experiment in experiments:\n",
    "    for _ in range(experiment):\n",
    "        sample = np.random.exponential(scale=1/lambda_val, size=sample_size)\n",
    "        sample_mean = np.mean(sample)\n",
    "        median = np.median(sample)\n",
    "        \n",
    "        lower_bound = sample_mean - z_alpha_2 * sample_std_mean\n",
    "        upper_bound = sample_mean + z_alpha_2 * sample_std_mean\n",
    "        \n",
    "        if lower_bound <= lambda_val <= upper_bound:\n",
    "            covered_count += 1\n",
    "\n",
    "    coverage_probability = covered_count / experiment\n",
    "\n",
    "    print(\"–ê—Å–∏–º–ø—Ç–æ—Ç–∏—á–µ—Å–∫–∏–π –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª —É—Ä–æ–≤–Ω—è\", 1-alpha, \"–¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ lambda:\", (lower_bound, upper_bound))\n",
    "    print(\"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–∫—Ä—ã—Ç–∏—è –∏—Å—Ç–∏–Ω–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ lambda: {:.2f}\".format(coverage_probability))\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
